\documentclass[polish,polish,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage{anysize}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{pgfplots}
\usepackage{xcolor} % do komentarzy
\usepackage{diagbox} % macierz pomyłek
\usepackage{color, colortbl}

\definecolor{Gray}{gray}{0.9}

\marginsize{2cm}{2cm}{2cm}{2cm}

\title{Wykrywanie naczyń dna siatkówki oka}
\author{Przemysław Ambroży (141182), Błażej Celmer (141197)}

\begin{document} 
	\maketitle
	
	\section{Wstęp}
		Ćwiczenie zakłada wykrycie oraz zaznaczenie naczyń na zdjęciach dna oka. 
		Skorzystamy z technik przetwarzania obrazu, uczenia maszynowego oraz głębokiej sieci neuronowej.
		Wyniki tych trzech metod porównamy ze sobą za pomocą wizualnej reprezentacji oraz miar jakości.
		
	\section{Środowisko}
		Skorzystaliśmy z języka Python w środowisku Jupyter Notebook,
		co pozwoliło uzyskać interfejs użytkownika niskim kosztem.
		Skorzystaliśmy również z bibliotek, które oferowały dodatkowe funkcjonalności, m.in.:
		
		\begin{description}
			\item[skimage] przetwarzanie obrazów
			\item [scipy] \texttt{\color{red} obliczanie momentów?}
			\item [sklearn] podział zdjęcia na fragmenty \texttt{\color{red} train\_test\_split?}
			\item [keras] sieci neuronowe 
			\item [pickle] zapis oraz odczyt wytrenowanych klasyfikatorów
		\end{description}
		
	\section{Opis metod}
		\subsection{Przetwarzanie obrazu}
			\begin{enumerate}
				\item skala szarości -- 
					skupiamy się jedynie na jasności obrazu
					
				\item dostosowanie gamma --
				
				\item dostosowanie ekspozycji --
				
				\item rozmycie --
					rozmycie gaussowskie  powinno zmniejszyć szum, który uwydatniłby się po wyostrzeniu
				
				\item wyostrzenie --
					uwydatnia granice naczyń
					
				\item wykrywanie krawędzi --
					uwydatnia granice naczyń, algorytm frangi
					
				\item maska binarna -- 
					funkcja ustalająca poziom odcięcia, 
					dzięki któremu wyznaczamy klasyfikację binarną
					
				\item otwarcie -- 
					funkcja wykonująca operacje erozji oraz dylatacji, 
					pozwala zmniejszyć szum
					
				\item usunięcie okręgu -- 
					powyższe operacje wygenerują jasny okrąg dookoła oka. Ta operacja zniweluje ten efekt poprzez nadpisanie.
			\end{enumerate}
		
		\subsection{Uczenie maszynowe}
			Na początek wstępnie edytujemy obraz wejściowy. Używamy niektórych funkcji z przetwarzania obrazu tj.:
			\begin{itemize}
				\item dostosowanie gamma
				\item dostosowanie ekspozycji
				\item rozmycie gaussowskie
				\item wyostrzenie
			\end{itemize}
			W kolejnym kroku dzielimy obraz na fragmenty o określonym rozmiarze (zazwyczaj od 5x5 do 9x9 pikseli).
			Te fragmenty zachodzą na siebie, tak każdy piksel ze zdjęcia posiadał fragment, w którym on jest na środku.
			Z pobranych fragmentów usuwamy te, które są poza obszarem oka (czarne tło).
			Następnie wybieramy losowe próbki ze zdjęcia w proporcji 50\% z klasy negatywnej i 50\% z pozytywnej.
			Każdą próbkę zamieniamy na zestaw cech dla klasyfikatora.
			W naszym przypadku jest to wektor wartości RGB kolejnych pikseli w fragmencie. 
			Proces jest powtarzany dla kilku zdjęć wejściowych, aby otrzymać więcej danych.
			
			Uczymy klasyfikator, korzystając z wygenerowanych cech wraz z odpowiadającym im wynikiem z maski eksperckiej. 
			Nasz klasyfikator to las decyzyjny (sklearn.tree.DecisionTreeClassifier).
			Został wytrenowany na zbiorze 500000 losowych próbek o rozmiarze 9x9 z zdjęć 
			\textit{01L}, \textit{01R}, \textit{02R}, \textit{03L}, \textit{03R}.
		
		\subsection{Głęboka sieć neuronowa}
			Obraz, przed wejściem do sieci, dzielony jest na fragmenty o wielkości 19x19 pikseli.
Następnie na każdym fragmencie wykonywana jest globalna normalizacja kontrastu.
Obliczana jest średnia i odchylenie standardowe każdego kanału we fragmencie (czerwony, zielony i niebieski).
Następnie każdy kanał każdego piksela jest normalizowany —- odejmowana
jest od niego średnia i dzielony jest przez odchylenie standardowe.
Poniżej przedstawione zostało działanie tej funkcji na wybranym fragmencie:
\\ wstawić porównanie
Do trenowania wykorzystano 500 tysięcy losowych fragmentów pochodzących z plików \textit{01L}, \textit{01R}, \textit{02L}, \textit{02R}, \textit{03L}, \textit{03R}. Dane zostały następnie podzielone na zbiór treningowy (67%) i testowy (33%).

Sieć została stworzona z wykorzystaniem biblioteki \texttt{keras}.
Składa się z 23 warstw i przypomina architekturę U-Net. 
Początkowo zastosowano dwie warstwy konwolucyjne o filtrze (wymiarowości wyjścia) równym 32 i rozmiarze okna 3x3.
Następnie zastosowano warstwę max pooling o oknie 2x2 przemieszczającym się o 2, która zmniejsza wielkość wyjścia.
Taki zestaw warstw powtórzono, zmieniając filtr na wartości: 48, 64, 96, 64, 38, 32.
Na końcu zastosowano warstwę wypłaszczającą oraz warstwę, gdzie każdy neuron jest połączony ze sobą (Dense) o sigmoidalnej funkcji aktywacji.

Do danych z wyjścia sieci zastosowano próg 0.3, powyżej którego piksel uznawany jest za naczynie.

Wstępna ocena sieci na danych testowych:
\begin{itemize}
    \item strata (loss) = 8.39%
    \item trafność (accuracy) = 96.99%
\end{itemize}

\subsubsection*{Rozmiar wycinka}
Zastosowano rozmiar wycinka 19x19. Mniejsze wycinki powodowały pogorszenie parametrów, przy większych czas tworzenia fragmentów i wstępnego przetwarzania był bardzo długi. Poniżej porównanie miar dla tego samego obrazka przy zastosowaniu różnych wycinków:

\begin{tabular}{|r|c|c|}
\hline
box               & 17                                            & 19                                            \\ \hline \hline
TP                & 59039                                         & 58529                                         \\ \hline
TN                & 829336                                        & 830092                                        \\ \hline
FP                & 23448                                         & 18842                                         \\ \hline
FN                & 16129                                         & 16639                                         \\ \hline
accuracy          & 0.9574                                        & 0.9616                                        \\ \hline
sensitivity       & 0.7854                                        & 0.7786                                        \\ \hline
specificity       & 0.9725                                        & 0.9778                                        \\ \hline
balanced accuracy & 0.879                                         & 0.8782                                        \\ \hline
F1                & 0.749                                         & 0.7674                                        \\ \hline
Obraz             & \includegraphics[width=4cm]{./dane/box17.jpg} & \includegraphics[width=4cm]{./dane/box19.jpg} \\ \hline
\end{tabular}		
		
	\section{Wyniki}
		Obrazy wynikowe dla poszczególnych metod są przedstawione jako porównanie z maską ekspercką.
		\begin{description}
			\item [zielony] prawdziwie pozytywna
			\item [żółty] fałszywie pozytywna
			\item [czerwony] fałszywie negatywna
			\item [czarny] prawdziwie negatywna
		\end{description}
\newpage
	
		\subsection{04L}

\begin{figure}[!h]
	\centering
	\begin{minipage}{0.26\linewidth}
		\includegraphics[width=\linewidth]{../chase/Image_04L.jpg}
		\centering
			\small{obraz wejściowy}
	\end{minipage}
	\hfill
	\begin{minipage}{0.26\linewidth}
		\includegraphics[width=\linewidth]{../chase/Image_04L_1stHO.png}
		\centering
			\small{maska ekspercka}
	\end{minipage}
\end{figure}
\input{./dane/przetwarzanie obrazu/04L.txt}
\input{./dane/uczenie maszynowe/04L.txt}
\input{./dane/głęboka sieć neuronowa/04L.txt}



		\subsection{05R}

\begin{figure}[!h]
	\centering
	\begin{minipage}{0.26\linewidth}
		\includegraphics[width=\linewidth]{../chase/Image_05R.jpg}
		\centering
			\small{obraz wejściowy}
	\end{minipage}
	\hfill
	\begin{minipage}{0.26\linewidth}
		\includegraphics[width=\linewidth]{../chase/Image_05R_1stHO.png}
		\centering
			\small{maska ekspercka}
	\end{minipage}
\end{figure}

\input{./dane/przetwarzanie obrazu/05R.txt}
\input{./dane/uczenie maszynowe/05R.txt}
\input{./dane/głęboka sieć neuronowa/05R.txt}



		\subsection{06L}

\begin{figure}[!h]
	\centering
	\begin{minipage}{0.26\linewidth}
		\includegraphics[width=\linewidth]{../chase/Image_06L.jpg}
		\centering
			\small{obraz wejściowy}
	\end{minipage}
	\hfill
	\begin{minipage}{0.26\linewidth}
		\includegraphics[width=\linewidth]{../chase/Image_06L_1stHO.png}
		\centering
			\small{maska ekspercka}
	\end{minipage}
\end{figure}
\input{./dane/przetwarzanie obrazu/06L.txt}
\input{./dane/uczenie maszynowe/06L.txt}
\input{./dane/głęboka sieć neuronowa/06L.txt}



		\subsection{07R}
		
\begin{figure}[!h]
	\centering
	\begin{minipage}{0.26\linewidth}
		\includegraphics[width=\linewidth]{../chase/Image_07R.jpg}
		\centering
			\small{obraz wejściowy}
	\end{minipage}
	\hfill
	\begin{minipage}{0.26\linewidth}
		\includegraphics[width=\linewidth]{../chase/Image_07R_1stHO.png}
		\centering
			\small{maska ekspercka}
	\end{minipage}
\end{figure}
\input{./dane/przetwarzanie obrazu/07R.txt}
\input{./dane/uczenie maszynowe/07R.txt}
\input{./dane/głęboka sieć neuronowa/07R.txt}



		\subsection{08L}

\begin{figure}[!h]
	\centering
	\begin{minipage}{0.26\linewidth}
		\includegraphics[width=\linewidth]{../chase/Image_08L.jpg}
		\centering
			\small{obraz wejściowy}
	\end{minipage}
	\hfill
	\begin{minipage}{0.26\linewidth}
		\includegraphics[width=\linewidth]{../chase/Image_08L_1stHO.png}
		\centering
			\small{maska ekspercka}
	\end{minipage}
\end{figure}
\input{./dane/przetwarzanie obrazu/08L.txt}
\input{./dane/uczenie maszynowe/08L.txt}
\input{./dane/głęboka sieć neuronowa/08L.txt}


	
	\section{Wnioski}
		
\end{document}