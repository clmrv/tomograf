{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import filters, exposure, feature, morphology, measure, filters\n",
    "from skimage.color import rgb2gray\n",
    "import scipy.stats as stats\n",
    "import sklearn.feature_extraction\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn import svm, tree\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, title=\"\", preview = True):\n",
    "    if preview:\n",
    "        plt.figure(figsize = (5,5))\n",
    "        plt.title(title)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "def load(id, preview = False):\n",
    "    img = plt.imread(f\"chase/Image_{id}.jpg\")\n",
    "    imshow(img, \"Obraz oryginalny\", preview)\n",
    "    \n",
    "    ref = plt.imread(f\"chase/Image_{id}_1stHO.png\")\n",
    "    imshow(ref, \"Obraz referencyjny\", preview)\n",
    "    \n",
    "    return (img, ref)\n",
    "\n",
    "def mask(image):\n",
    "    (h, w) = image.shape\n",
    "    center = (int(w/2), int(h/2))\n",
    "    radius = min(center[0], center[1], w-center[0], h-center[1]) * 0.92\n",
    "\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n",
    "\n",
    "    image[dist_from_center > radius] = 0\n",
    "    \n",
    "def get_picture_data(img, ref, box=5):\n",
    "    patches = sklearn.feature_extraction.image.extract_patches_2d(img, (box,box))\n",
    "    \n",
    "    to_slice = box//2\n",
    "\n",
    "    main_squares = ref[to_slice : -to_slice, to_slice : -to_slice].flatten()\n",
    "\n",
    "    return (patches, main_squares)\n",
    "\n",
    "def analysis(img, ref):\n",
    "    (rows, columns) = ref.shape\n",
    "    output_img = []\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    for r in range(rows):\n",
    "        output_img.append([])\n",
    "        for c in range(columns):\n",
    "            if ref[r][c] == 1:\n",
    "                if img[r][c] == 1:\n",
    "                    tp += 1\n",
    "                    output_img[r].append([0,255,0]) #green\n",
    "                else:\n",
    "                    fn += 1\n",
    "                    output_img[r].append([255,0,0]) #red\n",
    "            else:\n",
    "                if img[r][c] == 1:\n",
    "                    fp += 1\n",
    "                    output_img[r].append([255,255,0]) #yellow\n",
    "                else:\n",
    "                    tn += 1\n",
    "                    output_img[r].append([0,0,0]) #black\n",
    "    pop = tp + fn + fp + tn\n",
    "    \n",
    "    accuracy = (tp + tn) / pop\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    balanced_accuracy = (sensitivity + specificity) / 2\n",
    "    f1 = (2 * tp) / (2 * tp + fp + fn)\n",
    "    \n",
    "    imshow(output_img, \"Porównanie wyniku z obrazem referencyjnym\", True)\n",
    "    \n",
    "    print(f\"True positive:\\t{tp}\\t(zielony)\")\n",
    "    print(f\"True negative:\\t{tn}\\t(czarny)\")\n",
    "    print(f\"False positive:\\t{fp}\\t(żółty)\")\n",
    "    print(f\"False negative:\\t{fn}\\t(czerwony)\")\n",
    "    print(f\"Accuracy (trafność):\\t\\t{accuracy}\")\n",
    "    print(f\"Sensitivity (czułość):\\t\\t{sensitivity}\")\n",
    "    print(f\"Specificity (swoistość):\\t{specificity}\")\n",
    "    print(f\"Balanced accuracy:\\t\\t{balanced_accuracy}\")\n",
    "    print(f\"F1 score:\\t\\t\\t{f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-valuation",
   "metadata": {},
   "source": [
    "# Metoda 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_1(img, preview = False):\n",
    "    \n",
    "    img = rgb2gray(img)\n",
    "    \n",
    "    img = exposure.adjust_gamma(img, 0.5)\n",
    "    imshow(img, \"Gamma\", preview)\n",
    "    \n",
    "    img = exposure.rescale_intensity(img)\n",
    "    imshow(img, \"Ekspozycja\", preview)\n",
    "\n",
    "    filtered = filters.gaussian(img, 3)\n",
    "    imshow(filtered, \"Rozmycie\", preview)\n",
    "    \n",
    "    filtered = filters.unsharp_mask(img, 10)\n",
    "    imshow(filtered, \"Wyostrzenie\", preview)\n",
    "\n",
    "    edges = filters.frangi(filtered)\n",
    "    imshow(edges, \"Krawędzie\", preview)\n",
    "\n",
    "    binary = edges > filters.threshold_triangle(edges, 512)\n",
    "    imshow(binary, \"Maska binarna\", preview)\n",
    "    \n",
    "    f = morphology.binary_opening(binary)\n",
    "    imshow(f, \"Opening\", preview)\n",
    "    \n",
    "    mask(f)\n",
    "    imshow(f, \"Usunięcie okręgu\", preview)\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-decrease",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(img, ref) = load(\"01L\", False)\n",
    "\n",
    "print(\"Metoda 1\")\n",
    "m1 = method_1(img, False)\n",
    "analysis(m1, ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-tenant",
   "metadata": {},
   "source": [
    "# Klasyfikator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def features(frag):\n",
    "# #     hu_r = measure.moments_hu(frag[:,:,0])\n",
    "# #     hu_g = measure.moments_hu(frag[:,:,1])\n",
    "# #     hu_b = measure.moments_hu(frag[:,:,2])\n",
    "# #     return hu_r + hu_g + hu_b \n",
    "\n",
    "#     r = frag[:,:,0].flatten()\n",
    "#     g = frag[:,:,1].flatten()\n",
    "#     b = frag[:,:,2].flatten()\n",
    "    \n",
    "# #     variant = [np.var(r), np.var(g), np.var(b)]\n",
    "# #     return variant\n",
    "#     moment = [stats.moment(r, 3), stats.moment(g, 3), stats.moment(b, 3)]\n",
    "#     hu_r = measure.moments_hu(frag[:,:,0])\n",
    "#     hu_g = measure.moments_hu(frag[:,:,1])\n",
    "#     hu_b = measure.moments_hu(frag[:,:,2])\n",
    "    \n",
    "#     return moment + list(hu_r) + list(hu_g) + list(hu_b)\n",
    "# #     hu_mean = list(np.mean(np.array([hu_r, hu_g, hu_b]), axis=0))\n",
    "\n",
    "# #     return variant + moment + hu_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(frag):\n",
    "    return frag.flatten().flatten()\n",
    "\n",
    "def features_2(frag):\n",
    "    hu_r = measure.moments_hu(frag[:,:,0])\n",
    "    hu_g = measure.moments_hu(frag[:,:,1])\n",
    "    hu_b = measure.moments_hu(frag[:,:,2])\n",
    "    moments = stats.moment(np.sum(frag, axis=2), 3)\n",
    "    return list(hu_r) + list(hu_g) + list(hu_b) + list(moments)\n",
    "\n",
    "def features_p(frag):\n",
    "    hu_r = measure.moments_hu(frag[:,:,0])\n",
    "    hu_g = measure.moments_hu(frag[:,:,1])\n",
    "    hu_b = measure.moments_hu(frag[:,:,2])\n",
    "    return list(filters.prewitt(rgb2gray(frag)).flatten()) + list(hu_r) + list(hu_g) + list(hu_b)\n",
    "\n",
    "def features_pvh(frag):\n",
    "    hu_r = measure.moments_hu(frag[:,:,0])\n",
    "    hu_g = measure.moments_hu(frag[:,:,1])\n",
    "    hu_b = measure.moments_hu(frag[:,:,2])\n",
    "    return list(filters.prewitt_v(rgb2gray(frag)).flatten()) + list(filters.prewitt_h(rgb2gray(frag)).flatten()) + list(hu_r) + list(hu_g) + list(hu_b)\n",
    "\n",
    "def before_retouch(img):\n",
    "    img = exposure.adjust_gamma(img, 0.5)\n",
    "    img = exposure.rescale_intensity(img)\n",
    "    filtered = filters.gaussian(img, 3, multichannel=True)\n",
    "    filtered = filters.unsharp_mask(img, 10)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_only_zeros(listt):\n",
    "    # listt[row][col][rbg_value]\n",
    "    for value in listt.flatten().flatten().flatten():\n",
    "        if value != 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def beforeRetouch(img):\n",
    "    img = exposure.adjust_gamma(img, 0.5)\n",
    "    img = exposure.rescale_intensity(img)\n",
    "    filtered = filters.gaussian(img, 3, multichannel=True)\n",
    "    filtered = filters.unsharp_mask(img, 10)\n",
    "    return filtered\n",
    "\n",
    "def getTrainingDataFromImage( id, box, remove0=True, data5050=True ):\n",
    "    (img, ref) = load(id, False)\n",
    "    img = beforeRetouch(img)\n",
    "    (patches, refs) = get_picture_data(img, ref, box)\n",
    "    \n",
    "    print(\"All patches, refs: \", len(patches), len(refs))\n",
    "    \n",
    "    if (remove0):\n",
    "        indexesToRemove = []\n",
    "        for i in range(len(patches)):\n",
    "            if (check_if_only_zeros(patches[i]) ):\n",
    "                indexesToRemove.append(i)\n",
    "\n",
    "        indexesToRemove.pop(0)\n",
    "        print(\"To remove (0,0,0): \", len(indexesToRemove))\n",
    "        patches = np.delete(patches, indexesToRemove, axis=0)\n",
    "        refs = np.delete(refs, indexesToRemove, axis=0)\n",
    "        print(\"After removing: \", len(patches))\n",
    "\n",
    "    if (data5050):\n",
    "        refs_positive = refs[refs == True]\n",
    "        patches_positive = patches[refs == True]\n",
    "\n",
    "        refs_negative = refs[refs == False]\n",
    "        patches_negative = patches[refs == False]\n",
    "        print(\"Positive (patches, refs): \", len(patches_positive), len(refs_positive))\n",
    "        print(\"Negative (patches, refs): \", len(patches_negative), len(refs_negative))\n",
    "\n",
    "        sample_indexes = random.sample( range(len(refs_negative)), len(refs_positive))\n",
    "\n",
    "        patches = np.append(patches_positive, patches_negative[sample_indexes], axis=0)\n",
    "        refs = np.append(refs_positive, refs_negative[sample_indexes], axis = 0)\n",
    "        print(\"Img data to sample from (patches, refs): \", len(patches), len(refs), \"\\n\")\n",
    "    \n",
    "    feats = [features(f) for f in patches]\n",
    "    return (feats, refs)\n",
    "\n",
    "def getTrainingData( imgIdList, sampleCount, box=5, remove0=True, data5050=True ):\n",
    "    allFeats = []\n",
    "    allRefs = []\n",
    "    for imgId in imgIdList:\n",
    "        print(\"Loading\", imgId)\n",
    "        (feats, refs) = getTrainingDataFromImage(imgId, box, remove0, data5050)\n",
    "        allFeats += list(feats)\n",
    "        allRefs += list(refs)\n",
    "        \n",
    "    print(\"All img data to sample from: \",len(allFeats))\n",
    "    \n",
    "    return random.sample(list(zip(allFeats, allRefs)), sampleCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-bikini",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sample = getTrainingData([\"01L\", \"01R\", \"02L\", \"02R\", \"03L\", \"03R\", \"04L\", \"04R\"], 400000, 7)\n",
    "sample = getTrainingData([\"01L\", \"01R\"], 100000, 5, remove0=False, data5050=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit([f for f, _ in sample], [r for _, r in sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Zapis klasyfikatora do pliku\n",
    "pickle.dump(clf, open(\"clf\", \"wb\"))\n",
    "\n",
    "# Odczyt klasyfikatora z pliku\n",
    "clf = pickle.load(open(\"clf\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testfunction(estimator, id, box=5):\n",
    "    (img, ref) = load(id, False)\n",
    "    img = before_retouch(img)\n",
    "    (patches, refs) = get_picture_data(img, ref, box)\n",
    "    feats = [features(f) for f in patches]\n",
    "    \n",
    "    predicted = estimator.predict(feats)\n",
    "    print('sum of predicted', sum(predicted))\n",
    "\n",
    "    predicted_2d = np.reshape(predicted, (img.shape[0] - box + 1, img.shape[1] - box + 1))\n",
    "    refs_2d = np.reshape(refs, (img.shape[0] - box + 1, img.shape[1] - box + 1))\n",
    "\n",
    "    return (predicted_2d, refs_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-drill",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(predicted_2d, ref_2d) = testfunction(clf, \"05L\", 5)\n",
    "plt.imshow(predicted_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2d = morphology.dilation(predicted_2d)\n",
    "plt.imshow(p2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(p2d, ref_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-nutrition",
   "metadata": {},
   "source": [
    "# Sieć neuronowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Conv2D, Dense, MaxPooling2D, ThresholdedReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(ids, sampleCount, test_size=0.33, box=5):\n",
    "    allPatches = []\n",
    "    allRefs = []\n",
    "    for imgId in ids:\n",
    "        print(\"Loading\", imgId)\n",
    "        (img, ref) = load(imgId, False)\n",
    "        img = before_retouch(img)\n",
    "        (patches, refs) = get_picture_data(img, ref, box)\n",
    "        allPatches.append(patches)\n",
    "        allRefs.append(refs)\n",
    "        \n",
    "    # Join data from all images\n",
    "    allPatches = np.concatenate(allPatches, axis=0)\n",
    "    allRefs = np.concatenate(allRefs, axis=0)\n",
    "    \n",
    "    # Delete data\n",
    "    indexes = random.sample(range(allPatches.shape[0]), k=allPatches.shape[0] - sampleCount)\n",
    "    allPatches = np.delete(allPatches, indexes, axis=0)\n",
    "    allRefs = np.delete(allRefs, indexes, axis=0)\n",
    "    \n",
    "    print(allPatches.shape)\n",
    "    print(allRefs.shape)\n",
    "    \n",
    "    return train_test_split(allPatches, allRefs, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = get_train_test_data([\"01L\", \"01R\", \"02L\", \"02R\", \"03L\", \"03R\"], 800000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, 4, activation='relu'))\n",
    "model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(128, 3, padding='same', activation='relu'))\n",
    "model.add(Conv2D(128, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Trafność klasyfikacji to: {acc}%\".format(acc=accuracy*100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "(img2, ref2) = load(\"04R\", False)\n",
    "img2 = before_retouch(img2)\n",
    "(patches2, refs2) = get_picture_data(img2, ref2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = model.predict(patches2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_2d = np.reshape(pr, (img2.shape[0] - 5 + 1, img2.shape[1] - 5 + 1))\n",
    "pr_2d_th = pr_2d > 0.3\n",
    "refs2_2d = np.reshape(refs2, (img2.shape[0] - 5 + 1, img2.shape[1] - 5 + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pr_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pr_2d_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(pr_2d_th, refs2_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
