{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import filters, exposure, feature, morphology, measure, filters\n",
    "from skimage.color import rgb2gray\n",
    "import scipy.stats as stats\n",
    "import sklearn.feature_extraction\n",
    "import random\n",
    "from sklearn import svm, tree\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, title=\"\", preview = True):\n",
    "    if preview:\n",
    "        plt.figure(figsize = (5,5))\n",
    "        plt.title(title)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "def load(id, preview = False):\n",
    "    img = plt.imread(f\"chase/Image_{id}.jpg\")\n",
    "    imshow(img, \"Obraz oryginalny\", preview)\n",
    "    \n",
    "    ref = plt.imread(f\"chase/Image_{id}_1stHO.png\")\n",
    "    imshow(ref, \"Obraz referencyjny\", preview)\n",
    "    \n",
    "    return (img, ref)\n",
    "\n",
    "def mask(image):\n",
    "    (h, w) = image.shape\n",
    "    center = (int(w/2), int(h/2))\n",
    "    radius = min(center[0], center[1], w-center[0], h-center[1]) * 0.92\n",
    "\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n",
    "\n",
    "    image[dist_from_center > radius] = 0\n",
    "    \n",
    "def get_picture_data(img, ref, box=5):\n",
    "    patches = sklearn.feature_extraction.image.extract_patches_2d(img, (box,box))\n",
    "    \n",
    "    to_slice = box//2\n",
    "\n",
    "    main_squares = ref[to_slice : -to_slice, to_slice : -to_slice].flatten()\n",
    "\n",
    "    return (patches, main_squares)\n",
    "\n",
    "def analysis(img, ref):\n",
    "    (rows, columns) = ref.shape\n",
    "    output_img = []\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    for r in range(rows):\n",
    "        output_img.append([])\n",
    "        for c in range(columns):\n",
    "            if ref[r][c] == 1:\n",
    "                if img[r][c] == 1:\n",
    "                    tp += 1\n",
    "                    output_img[r].append([0,255,0]) #green\n",
    "                else:\n",
    "                    fn += 1\n",
    "                    output_img[r].append([255,0,0]) #red\n",
    "            else:\n",
    "                if img[r][c] == 1:\n",
    "                    fp += 1\n",
    "                    output_img[r].append([255,255,0]) #yellow\n",
    "                else:\n",
    "                    tn += 1\n",
    "                    output_img[r].append([0,0,0]) #black\n",
    "    pop = tp + fn + fp + tn\n",
    "    \n",
    "    accuracy = (tp + tn) / pop\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    balanced_accuracy = (sensitivity + specificity) / 2\n",
    "    f1 = (2 * tp) / (2 * tp + fp + fn)\n",
    "    \n",
    "    imshow(output_img, \"Porównanie wyniku z obrazem referencyjnym\", True)\n",
    "    \n",
    "    print(f\"True positive:\\t{tp}\\t(zielony)\")\n",
    "    print(f\"True negative:\\t{tn}\\t(czarny)\")\n",
    "    print(f\"False positive:\\t{fp}\\t(żółty)\")\n",
    "    print(f\"False negative:\\t{fn}\\t(czerwony)\")\n",
    "    print(f\"Accuracy (trafność):\\t\\t{accuracy}\")\n",
    "    print(f\"Sensitivity (czułość):\\t\\t{sensitivity}\")\n",
    "    print(f\"Specificity (swoistość):\\t{specificity}\")\n",
    "    print(f\"Balanced accuracy:\\t\\t{balanced_accuracy}\")\n",
    "    print(f\"F1 score:\\t\\t\\t{f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-supplier",
   "metadata": {},
   "source": [
    "# Metoda 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_1(img, preview = False):\n",
    "    \n",
    "    img = rgb2gray(img)\n",
    "    \n",
    "    img = exposure.adjust_gamma(img, 0.5)\n",
    "    imshow(img, \"Gamma\", preview)\n",
    "    \n",
    "    img = exposure.rescale_intensity(img)\n",
    "    imshow(img, \"Ekspozycja\", preview)\n",
    "\n",
    "    filtered = filters.gaussian(img, 3)\n",
    "    imshow(filtered, \"Rozmycie\", preview)\n",
    "    \n",
    "    filtered = filters.unsharp_mask(img, 10)\n",
    "    imshow(filtered, \"Wyostrzenie\", preview)\n",
    "\n",
    "    edges = filters.frangi(filtered)\n",
    "    imshow(edges, \"Krawędzie\", preview)\n",
    "\n",
    "    binary = edges > filters.threshold_triangle(edges, 512)\n",
    "    imshow(binary, \"Maska binarna\", preview)\n",
    "    \n",
    "    f = morphology.binary_opening(binary)\n",
    "    imshow(f, \"Opening\", preview)\n",
    "    \n",
    "    mask(f)\n",
    "    imshow(f, \"Usunięcie okręgu\", preview)\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-decrease",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(img, ref) = load(\"01L\", False)\n",
    "\n",
    "print(\"Metoda 1\")\n",
    "m1 = method_1(img, False)\n",
    "analysis(m1, ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-sleep",
   "metadata": {},
   "source": [
    "# Klasyfikator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def features(frag):\n",
    "# #     hu_r = measure.moments_hu(frag[:,:,0])\n",
    "# #     hu_g = measure.moments_hu(frag[:,:,1])\n",
    "# #     hu_b = measure.moments_hu(frag[:,:,2])\n",
    "# #     return hu_r + hu_g + hu_b \n",
    "\n",
    "#     r = frag[:,:,0].flatten()\n",
    "#     g = frag[:,:,1].flatten()\n",
    "#     b = frag[:,:,2].flatten()\n",
    "    \n",
    "# #     variant = [np.var(r), np.var(g), np.var(b)]\n",
    "# #     return variant\n",
    "#     moment = [stats.moment(r, 3), stats.moment(g, 3), stats.moment(b, 3)]\n",
    "#     hu_r = measure.moments_hu(frag[:,:,0])\n",
    "#     hu_g = measure.moments_hu(frag[:,:,1])\n",
    "#     hu_b = measure.moments_hu(frag[:,:,2])\n",
    "    \n",
    "#     return moment + list(hu_r) + list(hu_g) + list(hu_b)\n",
    "# #     hu_mean = list(np.mean(np.array([hu_r, hu_g, hu_b]), axis=0))\n",
    "\n",
    "# #     return variant + moment + hu_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(frag):\n",
    "    return frag.flatten().flatten()\n",
    "\n",
    "def features_2(frag):\n",
    "    hu_r = measure.moments_hu(frag[:,:,0])\n",
    "    hu_g = measure.moments_hu(frag[:,:,1])\n",
    "    hu_b = measure.moments_hu(frag[:,:,2])\n",
    "    moments = stats.moment(np.sum(frag, axis=2), 3)\n",
    "    return list(hu_r) + list(hu_g) + list(hu_b) + list(moments)\n",
    "\n",
    "def features_p(frag):\n",
    "    hu_r = measure.moments_hu(frag[:,:,0])\n",
    "    hu_g = measure.moments_hu(frag[:,:,1])\n",
    "    hu_b = measure.moments_hu(frag[:,:,2])\n",
    "    return list(filters.prewitt(rgb2gray(frag)).flatten()) + list(hu_r) + list(hu_g) + list(hu_b)\n",
    "\n",
    "def features_pvh(frag):\n",
    "    hu_r = measure.moments_hu(frag[:,:,0])\n",
    "    hu_g = measure.moments_hu(frag[:,:,1])\n",
    "    hu_b = measure.moments_hu(frag[:,:,2])\n",
    "    return list(filters.prewitt_v(rgb2gray(frag)).flatten()) + list(filters.prewitt_h(rgb2gray(frag)).flatten()) + list(hu_r) + list(hu_g) + list(hu_b)\n",
    "\n",
    "def before_retouch(img):\n",
    "    img = exposure.adjust_gamma(img, 0.5)\n",
    "    img = exposure.rescale_intensity(img)\n",
    "    filtered = filters.gaussian(img, 3, multichannel=True)\n",
    "    filtered = filters.unsharp_mask(img, 10)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_only_zeros(listt):\n",
    "    for item in listt:\n",
    "        if item != 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def getTrainingDataFromImage( id, box=5 ):\n",
    "    (img, ref) = load(id, False)\n",
    "    img = before_retouch(img)\n",
    "    (patches, refs) = get_picture_data(img, ref, box)\n",
    "    feats = [features(f) for f in patches]\n",
    "\n",
    "    print(\"feats before: \", len(feats))\n",
    "    print(len(refs))\n",
    "\n",
    "    indexesToRemove = []\n",
    "    for i in range(len(feats)):\n",
    "        if(check_if_only_zeros(feats[i]) ):\n",
    "            indexesToRemove.append(i)\n",
    "\n",
    "    indexesToRemove.pop(0)\n",
    "\n",
    "    feats = np.delete(feats, indexesToRemove, axis=0)\n",
    "    refs = np.delete(refs, indexesToRemove, axis=0)\n",
    "\n",
    "    print(\"feats after: \", len(feats))\n",
    "    return (feats, refs)\n",
    "\n",
    "def getTrainingData( imgIdList, sampleCount, box=5 ):\n",
    "    allFeats = []\n",
    "    allRefs = []\n",
    "    for imgId in imgIdList:\n",
    "        print(\"Loading\", imgId)\n",
    "        (feats, refs) = getTrainingDataFromImage(imgId, box)\n",
    "        allFeats += list(feats)\n",
    "        allRefs += list(refs)\n",
    "    \n",
    "    return random.sample(list(zip(allFeats, allRefs)), sampleCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-bikini",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sample = getTrainingData([\"01L\", \"01R\", \"02L\", \"02R\", \"03L\", \"03R\", \"04L\", \"04R\"], 400000, 7)\n",
    "sample = getTrainingData([\"01L\", \"01R\"], 400000, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit([f for f, _ in sample], [r for _, r in sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Zapis klasyfikatora do pliku\n",
    "pickle.dump(clf, open(\"clf\", \"wb\"))\n",
    "\n",
    "# Odczyt klasyfikatora z pliku\n",
    "clf = pickle.load(open(\"clf\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testfunction(estimator, id, box=5):\n",
    "    (img, ref) = load(id, False)\n",
    "    img = before_retouch(img)\n",
    "    (patches, refs) = get_picture_data(img, ref, box)\n",
    "    feats = [features(f) for f in patches]\n",
    "    \n",
    "    predicted = estimator.predict(feats)\n",
    "    print('sum of predicted', sum(predicted))\n",
    "\n",
    "    predicted_2d = np.reshape(predicted, (img.shape[0] - box + 1, img.shape[1] - box + 1))\n",
    "    refs_2d = np.reshape(refs, (img.shape[0] - box + 1, img.shape[1] - box + 1))\n",
    "\n",
    "    return (predicted_2d, refs_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-drill",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(predicted_2d, ref_2d) = testfunction(clf, \"05L\", 7)\n",
    "plt.imshow(predicted_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2d = morphology.dilation(predicted_2d)\n",
    "plt.imshow(p2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(p2d, ref_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-sapphire",
   "metadata": {},
   "source": [
    "# Sieć neuronowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-assets",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
